# ============================================================================
# Dental Clinic AI Service v2.0 - Environment Configuration
# ============================================================================

# Application
ENVIRONMENT=development  # development, staging, production
LOG_LEVEL=INFO
DEBUG=true

# ============================================================================
# LLM Configuration
# ============================================================================

# Choose LLM Provider: anthropic or openai
LLM_PROVIDER=anthropic

# Anthropic API Key (required if LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Anthropic Model (options: claude-sonnet-4-5-20250929, claude-sonnet-4-20250514, claude-3-5-haiku-20241022)
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929

# OpenAI API Key (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your-openai-api-key-here

# OpenAI Model (options: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-4, gpt-3.5-turbo)
OPENAI_MODEL=gpt-4o-mini

# Global LLM behavior settings
LLM_MAX_TOKENS=1000
LLM_TEMPERATURE=0.7
LLM_TIMEOUT=30

# ============================================================================
# Component-Specific LLM Configuration
# ============================================================================
# Fine-tune LLM behavior for different components
# Lower temperatures (0.1-0.3) = deterministic, consistent
# Higher temperatures (0.7-1.0) = creative, varied

# Reasoning & Routing (intent classification, routing decisions)
REASONING_TEMPERATURE=0.3

# Validation (response quality checks)
VALIDATION_TEMPERATURE=0.2

# Finalization (final quality control)
FINALIZATION_TEMPERATURE=0.3

# Translation (language detection and translation)
TRANSLATION_TEMPERATURE=0.1

# Intent Router (intent classification)
INTENT_ROUTER_TEMPERATURE=0.3

# Agent Execution (agent responses, tool calling)
AGENT_TEMPERATURE=0.7

# Component-Specific Model Overrides (optional - leave blank to use global model)
# Useful for cost optimization (e.g., use cheaper models for translation)
REASONING_MODEL=
TRANSLATION_MODEL=
INTENT_ROUTER_MODEL=
AGENT_MODEL=

# ============================================================================
# Database (DB-Ops)
# ============================================================================

# DB-Ops Service URL
DB_OPS_URL=http://localhost:8001  # For local: localhost:8001, For Docker: db-ops:8001

# DB-Ops Authentication
DB_OPS_USER_EMAIL=admin@healthcareclinic.com
DB_OPS_USER_PASSWORD=your-db-ops-password

# Patient AI Service Auth Tokens (optional, will be obtained via login if not set)
PATIENT_AI_SERVICE_AUTH_TOKEN=
PATIENT_AI_SERVICE_REFRESH_TOKEN=

# ============================================================================
# Redis (Optional - for production state management)
# ============================================================================

REDIS_ENABLED=false  # Set to true for production
REDIS_URL=redis://localhost:6379

# ============================================================================
# Features
# ============================================================================

ENABLE_TRANSLATION=true
ENABLE_CLASSIFICATION=true
ENABLE_MEDICAL_INQUIRY=true
ENABLE_EMERGENCY_RESPONSE=true

# ============================================================================
# Clinic Configuration
# ============================================================================

DEFAULT_CLINIC_ID=clinic_001
CLINIC_NAME=Bright Smile Dental Clinic
CLINIC_PHONE=+971-XXX-XXXX
CLINIC_EMAIL=info@brightsmile.clinic

# ============================================================================
# Security
# ============================================================================

# CORS Origins (comma-separated)
# For development, use "*". For production, specify allowed origins.
CORS_ORIGINS=*

# ============================================================================
# Performance
# ============================================================================

MAX_SESSIONS=10000
MAX_CONCURRENT_REQUESTS=100
SESSION_TTL=86400  # 24 hours in seconds
ENABLE_CACHING=true
CACHE_TTL=3600  # 1 hour in seconds

# ============================================================================
# Configuration Tips & Optimization Strategies
# ============================================================================
#
# COST OPTIMIZATION:
# - Use cheaper models for non-critical components (translation, intent routing)
# - Example: TRANSLATION_MODEL=gpt-4o-mini or TRANSLATION_MODEL=claude-3-5-haiku-20241022
# - Example: INTENT_ROUTER_MODEL=gpt-4o-mini
# - Monitor costs with COST_TRACKING_ENABLED=true (in config.py)
# - Cost comparison:
#   * GPT-4o: $2.50/$10.00 per 1M tokens (input/output)
#   * GPT-4o-mini: $0.15/$0.60 per 1M tokens
#   * Claude Sonnet 4.5: $3.00/$15.00 per 1M tokens
#   * Claude Haiku: $0.25/$1.25 per 1M tokens
#
# QUALITY OPTIMIZATION:
# - Use premium models for agent execution
# - Example: AGENT_MODEL=gpt-4o or AGENT_MODEL=claude-sonnet-4-5-20250929
# - Keep reasoning with high-quality models for accurate routing
# - Example: REASONING_MODEL=claude-sonnet-4-5-20250929
#
# LATENCY OPTIMIZATION:
# - Use faster models across all components
# - Example: Set LLM_PROVIDER=openai and OPENAI_MODEL=gpt-4o-mini
# - Or: Set LLM_PROVIDER=anthropic and ANTHROPIC_MODEL=claude-3-5-haiku-20241022
# - Disable validation and finalization layers (set ENABLE_VALIDATION=false)
# - Reduce LLM_MAX_TOKENS for faster responses
#
# CONSISTENCY OPTIMIZATION:
# - Lower all temperature settings (0.1-0.3 range)
# - Use same model across all components
# - Example:
#   REASONING_TEMPERATURE=0.2
#   VALIDATION_TEMPERATURE=0.2
#   TRANSLATION_TEMPERATURE=0.2
#   AGENT_TEMPERATURE=0.2
#
# HYBRID APPROACH (Recommended for Production):
# - Premium model for agent execution (user-facing)
# - Fast, cheap models for internal processing
# - Example configuration:
#   LLM_PROVIDER=anthropic
#   ANTHROPIC_MODEL=claude-sonnet-4-5-20250929  # Default premium model
#   TRANSLATION_MODEL=claude-3-5-haiku-20241022  # Cheap for translation
#   REASONING_MODEL=  # Use default premium model for accuracy
#   AGENT_MODEL=  # Use default premium model for quality
#
# ============================================================================
